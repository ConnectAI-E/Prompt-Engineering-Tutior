1
00:00:05,000 --> 00:00:09,000
欢迎学习《面向开发者的 ChatGPT Prompt 工程》课程

2
00:00:09,000 --> 00:00:14,000
很高兴能邀请到 Isa Fulford 和我一起授课

3
00:00:14,000 --> 00:00:18,000
她是 OpenAI 的技术人员之一，曾建立了流行的

4
00:00:18,000 --> 00:00:23,000
ChatGPT 检索插件，她大部分工作是教人们

5
00:00:23,000 --> 00:00:27,000
如何在产品中使用LLM或大语言模型技术

6
00:00:27,000 --> 00:00:31,000
她还为OpenAI手册做出了贡献，教会人们如何使用提示

7
00:00:31,000 --> 00:00:32,000
所以，很高兴有你参与

8
00:00:32,000 --> 00:00:37,000
我也很高兴能在这里与大家分享一些提示的最佳实践

9
00:00:37,000 --> 00:00:42,000
在互联网上有很多关于提示资料以及一些文章

10
00:00:42,000 --> 00:00:45,000
比如，每个人都必须知道的30个提示

11
00:00:45,000 --> 00:00:50,000
许多人正在使用 ChatGPT 的 Web 用户界面

12
00:00:50,000 --> 00:00:54,000
来完成特定而且通常是一次性的任务

13
00:00:54,000 --> 00:01:00,000
但作为一名开发者，我认为LLMs和大语言模型的强大也是不可忽视的

14
00:01:00,000 --> 00:01:04,000
那就是通过API调用LLM来快速构建软件应用程序

15
00:01:04,000 --> 00:01:08,000
我认为这仍然被严重低估

16
00:01:08,000 --> 00:01:12,000
事实上，我在AI Fund的团队，也就是Deep Learning.AI的姐妹公司

17
00:01:12,000 --> 00:01:16,000
一直在与许多初创公司、不同项目合作

18
00:01:16,000 --> 00:01:18,000
来应用这些技术

19
00:01:18,000 --> 00:01:23,000
看到LLM API能够让开发者快速建立一些东西

20
00:01:23,000 --> 00:01:25,000
这很令人兴奋

21
00:01:25,000 --> 00:01:29,000
所以在这个课程中，我们将与你分享一些可能性

22
00:01:29,000 --> 00:01:34,000
你可以做什么，以及如何做的最佳实践

23
00:01:34,000 --> 00:01:36,000
这里会覆盖很多资料

24
00:01:36,000 --> 00:01:41,000
首先，你将学习一些软件开发的提示词最佳实践

25
00:01:41,000 --> 00:01:45,000
然后，我们将涵盖一些常见的用例、总结、推断

26
00:01:45,000 --> 00:01:50,000
转化、扩展，然后使用LLM建立一个聊天机器人

27
00:01:50,000 --> 00:01:53,000
我们希望这将激发你

28
00:01:53,000 --> 00:01:55,000
开发新应用的想象力

29
00:01:55,000 --> 00:01:58,000
因此，在大型语言模型或LLM的发展中

30
00:01:58,000 --> 00:02:02,000
大体上有两种类型的LLM，我把它们称为

31
00:02:02,000 --> 00:02:06,000
基础LLM和指令学习LLM

32
00:02:06,000 --> 00:02:11,000
基础LLM已经被训练成基于文本训练数据来预测下一个单词

33
00:02:11,000 --> 00:02:15,000
通常通过互联网和其他来源训练大量数据

34
00:02:15,000 --> 00:02:19,000
并计算出下一个最可能出现的词是什么

35
00:02:19,000 --> 00:02:24,000
比如，你输入这个提示："从前有一只独角兽"

36
00:02:24,000 --> 00:02:28,000
它会进行补全，并预测接下来的几个词是

37
00:02:28,000 --> 00:02:31,000
"和所有独角兽朋友一起生活在一个神奇的森林里"

38
00:02:31,000 --> 00:02:35,000
但是如果你是用"法国的首都是什么"作为提示

39
00:02:35,000 --> 00:02:40,000
那么根据互联网上的文章

40
00:02:40,000 --> 00:02:44,000
很有可能是，基础LLM会以下列方式完成这个任务

41
00:02:44,000 --> 00:02:48,000
什么是法国最大的城市，什么是法国的人口，等等

42
00:02:48,000 --> 00:02:52,000
因为互联网上的文章，可能会列出

43
00:02:52,000 --> 00:02:55,000
关于法国的小测验问题列表

44
00:02:55,000 --> 00:03:00,000
与此相反，指令学习LLM，发展势头较猛

45
00:03:00,000 --> 00:03:04,000
LLM的研究和实践一直在进行

46
00:03:04,000 --> 00:03:08,000
一个经过指令学习的LLM已经被训练得能够遵循指令

47
00:03:08,000 --> 00:03:11,000
因此，如果你问它，法国的首都是什么？

48
00:03:11,000 --> 00:03:15,000
它很可能输出法国的首都是巴黎

49
00:03:15,000 --> 00:03:19,000
因此，指令学习的LLM的典型训练方式是

50
00:03:19,000 --> 00:03:23,000
从一个在大量文本数据上训练过的基础LLM开始

51
00:03:23,000 --> 00:03:28,000
然后进一步训练它，用输入和输出来进一步微调它

52
00:03:28,000 --> 00:03:32,000
这些输入和输出都是指令，也是遵循这些指令的良好尝试

53
00:03:32,000 --> 00:03:36,000
然后经常使用一种叫做RLHF的技术进一步完善

54
00:03:36,000 --> 00:03:41,000
从人类反馈中进行强化学习，以使系统能够更好地

55
00:03:41,000 --> 00:03:43,000
提供帮助并遵循指令

56
00:03:43,000 --> 00:03:47,000
因为经过指令学习的LLM已经被训练得很有帮助

57
00:03:47,000 --> 00:03:51,000
诚实且无害，因此，举例来说，它们不太可能输出

58
00:03:51,000 --> 00:03:55,000
那些与基础LLM相比，会出问题的文本，如有害的输出

59
00:03:55,000 --> 00:03:59,000
很多实际应用场景已经开始向

60
00:03:59,000 --> 00:04:01,000
指令学习LLM转移

61
00:04:01,000 --> 00:04:04,000
你在互联网上找到的一些最佳实践可能更适用于基础LLM

62
00:04:04,000 --> 00:04:08,000
但对于今天的大多数实际应用情况来说，它们可能不太合适

63
00:04:08,000 --> 00:04:13,000
我们建议大多数人多关注指令学习LLM

64
00:04:13,000 --> 00:04:17,000
它们更容易使用，而且由于OpenAI

65
00:04:17,000 --> 00:04:22,000
和其他LLM公司的工作，也将变得更加安全和一致

66
00:04:22,000 --> 00:04:27,000
因此，本课程将重点介绍指令学习LLM的最佳实践

67
00:04:27,000 --> 00:04:32,000
这也是我们建议你在大多数应用中使用的

68
00:04:32,000 --> 00:04:36,000
在继续之前，我想感谢来自OpenAI

69
00:04:36,000 --> 00:04:39,000
和DeepLearning.ai的团队

70
00:04:39,000 --> 00:04:42,000
他们为我和Isa将要介绍的资料做出了贡献

71
00:04:42,000 --> 00:04:45,000
我非常感谢Andrew Main, Joe Palermo, Boris Power

72
00:04:45,000 --> 00:04:49,000
Ted Sanders，以及来自OpenAI的Lilian Wang

73
00:04:49,000 --> 00:04:53,000
与我们一起集思广益，审核资料

74
00:04:53,000 --> 00:04:55,000
并做成这个简短的课程

75
00:04:55,000 --> 00:04:58,000
我也很感谢DeepLearning方面的工作

76
00:04:58,000 --> 00:05:01,000
Jeff Ludwig、Eddie Hsu和Tommy Nelson的工作

77
00:05:01,000 --> 00:05:06,000
因此，当你使用一个指令学习LLM时，可以将其看作是

78
00:05:06,000 --> 00:05:10,000
向另一个人发出指令，比如一个聪明但不知道

79
00:05:10,000 --> 00:05:12,000
任务细节的人

80
00:05:12,000 --> 00:05:16,000
因此，当一个LLM不工作时，有时是因为指令

81
00:05:16,000 --> 00:05:17,000
不够清楚

82
00:05:17,000 --> 00:05:20,000
例如，如果你说，请给我写一些

83
00:05:20,000 --> 00:05:22,000
关于艾伦-图灵的东西

84
00:05:22,000 --> 00:05:26,000
那么，除此之外，明确以下几点也会有所帮助

85
00:05:26,000 --> 00:05:30,000
你想让文章侧重于他的科学工作

86
00:05:30,000 --> 00:05:34,000
他的个人生活、他在历史上的作用或其他方向

87
00:05:34,000 --> 00:05:39,000
如果你指定了想要文本的语调

88
00:05:39,000 --> 00:05:43,000
它是否会根据指定的语调来写，比如像专业记者写的那样

89
00:05:43,000 --> 00:05:46,000
还是更像随手写给朋友的轻松语气？

90
00:05:46,000 --> 00:05:47,000
这一点是成立的

91
00:05:47,000 --> 00:05:49,000
LLM会产生你想要的东西

92
00:05:49,000 --> 00:05:52,000
当然，如果你想象是自己在问，比如

93
00:05:52,000 --> 00:05:56,000
一个刚毕业的大学生为你完成这项任务

94
00:05:56,000 --> 00:05:59,000
如果你甚至可以指定他们应该阅读哪些文本片段

95
00:05:59,000 --> 00:06:02,000
提前写出这篇关于艾伦-图灵的文章

96
00:06:02,000 --> 00:06:06,000
那么，这能成功让那个刚毕业的大学生

97
00:06:06,000 --> 00:06:09,000
更好的为你完成这项任务

98
00:06:09,000 --> 00:06:13,000
因此，在接下来的视频中，你会看到如何清晰且明确

99
00:06:13,000 --> 00:06:17,000
描述提示，这是一个重要的LLM提示准则

100
00:06:17,000 --> 00:06:21,000
而且你还将从Isa那里学到了第二个提示词准则

101
00:06:21,000 --> 00:06:24,000
那就是给LLM时间来思考

102
00:06:24,000 --> 00:06:29,000
因此，让我们继续观看下一个视频

